üñ•Ô∏è AI Agent Development Instructions: Local Speech-to-Speech on Windows
1. Environment Setup

Install Python 3.10+ (from python.org
)

During install: ‚úÖ Check ‚ÄúAdd Python to PATH‚Äù.

Install Git (from git-scm.com
)

Install FFmpeg (needed for audio):

Download from ffmpeg.org

Extract and add the bin folder to PATH.

(Optional but recommended) Install Anaconda or Miniconda to manage environments.

2. Create a Virtual Environment
# Open PowerShell
python -m venv s2s_env
.\s2s_env\Scripts\activate

3. Install Required Libraries
pip install sounddevice numpy
pip install faster-whisper
pip install TTS


‚ö†Ô∏è If you have an NVIDIA GPU, also install PyTorch with CUDA:

pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121


(Replace cu121 with your CUDA version.)

4. Test Speech-to-Text (STT)

Create a file stt_test.py:

from faster_whisper import WhisperModel

model = WhisperModel("base", device="cuda")  # use "cpu" if no GPU
segments, _ = model.transcribe("sample.wav")  # put a test wav/mp3 file

for seg in segments:
    print(seg.text)


Run:

python stt_test.py


‚úÖ Should print transcription.

5. Test Text-to-Speech (TTS)

Create a file tts_test.py:

from TTS.api import TTS

tts = TTS(model_name="tts_models/en/ljspeech/tacotron2-DDC", progress_bar=False, gpu=True)
tts.tts_to_file(text="Hello, this is a test", file_path="output.wav")


Run:

python tts_test.py


‚úÖ Should generate output.wav with voice.

6. Build Speech-to-Speech Pipeline

Create s2s.py:

import sounddevice as sd
import numpy as np
from faster_whisper import WhisperModel
from TTS.api import TTS

# Load models
stt_model = WhisperModel("base", device="cuda")   # or "cpu"
tts_model = TTS(model_name="tts_models/en/ljspeech/tacotron2-DDC", progress_bar=False, gpu=True)

# Record speech
def record_audio(duration=5, samplerate=16000):
    print("üéôÔ∏è Speak now...")
    audio = sd.rec(int(duration * samplerate), samplerate=samplerate, channels=1, dtype="float32")
    sd.wait()
    return np.squeeze(audio)

# Step 1: Speech to Text
audio = record_audio(5)
segments, _ = stt_model.transcribe(audio)
text = " ".join([seg.text for seg in segments])
print("üìù Recognized:", text)

# Step 2: (Echo Mode, no LLM)
reply = text

# Step 3: Text to Speech
tts_model.tts_to_file(text=reply, file_path="reply.wav")
print("üîä Reply saved as reply.wav")


Run:

python s2s.py


üé§ Speak for 5 seconds ‚Üí it transcribes ‚Üí plays back your voice as TTS.

7. Optional Enhancements

Replace echo (reply = text) with a local LLM using Ollama
:

ollama pull mistral


Then send recognized text ‚Üí LLM ‚Üí TTS.

Swap TTS model to Piper for faster real-time voices.

Add continuous streaming mode for near real-time response.